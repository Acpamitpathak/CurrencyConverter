import os
from dotenv import load_dotenv
from semantic_kernel import Kernel
from semantic_kernel.connectors.ai.open_ai import AzureChatService

load_dotenv()

def setup_kernel():
    kernel = Kernel()

    # Azure credentials
    api_key = os.getenv("AZURE_OPENAI_API_KEY")
    endpoint = os.getenv("AZURE_OPENAI_ENDPOINT")
    deployment = os.getenv("AZURE_OPENAI_DEPLOYMENT_NAME")
    api_version = os.getenv("AZURE_OPENAI_API_VERSION")

    # Configuration for token, temperature, etc.
    azure_chat_service = AzureChatService(
        deployment_name=deployment,
        endpoint=endpoint,
        api_key=api_key,
        api_version=api_version,
        max_tokens=2048,         # ✅ Limit max tokens in response
        temperature=0.3,          # ✅ Lower = more deterministic
        top_p=0.9,                # Optional: controls nucleus sampling
        frequency_penalty=0.0,    # Optional
        presence_penalty=0.0      # Optional
    )

    kernel.add_chat_service("azure-gpt", azure_chat_service)
    kernel.set_default_chat_service("azure-gpt")

    return kernel




result = await self.kernel.get_chat_service().complete_chat(prompt=final_prompt)